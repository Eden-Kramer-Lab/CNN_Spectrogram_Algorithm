{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# this is the main library used (sits on top of PyTorch)\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data: PATH should lead to the data folder with subfolders train, valid, and test. Train and valid should each have subfolders \"yes\" and \"no\". For this to run, you need something in these \"yes\" and \"no\" folders, though it won't affect the predictions--just put in some images from your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where the data is\n",
    "PATH = \"data/example_data\"\n",
    "# using resnet architecture\n",
    "arch = resnet34\n",
    "# size of square image in pixels\n",
    "sz = 44\n",
    "# transforms used on training data\n",
    "transforms_up_down = [RandomScale(sz,1.2),RandomRotate(1)]\n",
    "tfms = tfms_from_model(arch,sz,crop_type = CropType.NO,aug_tfms=transforms_up_down)\n",
    "# data: comes from PATH, used tfms on training data, bs of 8 for training data, test data located in test folder\n",
    "data = ImageClassifierData.from_paths(PATH,tfms=tfms,bs=8,test_name='test')\n",
    "# load in pretraine\n",
    "state = torch.load('saved_model.pkl',map_location=torch.device('cpu')) # remove map_location parameter if on GPU\n",
    "learn2 = ConvLearner.pretrained(arch,data,precompute=False)\n",
    "learn2.model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds_test = learn2.predict(is_test=True)\n",
    "preds_test = np.argmax(log_preds_test,axis=1)\n",
    "probs_test = np.exp(log_preds_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = np.empty_like(data.test_ds.fnames)\n",
    "for i in range(len(data.test_ds.fnames)):\n",
    "    test_names[i] = data.test_ds.fnames[i]\n",
    "    #temp = data.test_ds.fnames[i]\n",
    "    #matchobj = re.search('.*im.*',temp)\n",
    "    #test_names[i] = matchobj.group()\n",
    "test_df = pd.DataFrame(data = test_names,columns = ['image_number'])\n",
    "test_df['prediction'] = preds_test\n",
    "test_df['probability'] = probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_number</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/new_img_350.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/new_img_436.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/new_img_422.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/new_img_344.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/new_img_378.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>test/new_img_361.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>test/new_img_407.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>test/new_img_413.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>test/new_img_375.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>test/new_img_349.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_number  prediction  probability\n",
       "0     test/new_img_350.jpg           0     0.000214\n",
       "1     test/new_img_436.jpg           0     0.000277\n",
       "2     test/new_img_422.jpg           0     0.000005\n",
       "3     test/new_img_344.jpg           1     0.973887\n",
       "4     test/new_img_378.jpg           0     0.002214\n",
       "...                    ...         ...          ...\n",
       "1194  test/new_img_361.jpg           0     0.001094\n",
       "1195  test/new_img_407.jpg           0     0.035961\n",
       "1196  test/new_img_413.jpg           0     0.000799\n",
       "1197  test/new_img_375.jpg           0     0.000464\n",
       "1198  test/new_img_349.jpg           0     0.000084\n",
       "\n",
       "[1199 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
